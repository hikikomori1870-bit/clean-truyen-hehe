import re
import os
import traceback
import sys
import uuid
import zipfile
from datetime import datetime
import sys
import io
import html
import urllib.request
import json
import subprocess
import time
import concurrent.futures

CURRENT_VERSION = "1.0.2"
GITHUB_USER = "hikikomori1870-bit"
GITHUB_REPO = "clean-truyen-hehe"
VERSION_URL = f"https://raw.githubusercontent.com/{GITHUB_USER}/{GITHUB_REPO}/main/version.json"

def check_for_updates():
    print(f"\nüîç ƒêang ki·ªÉm tra b·∫£n c·∫≠p nh·∫≠t... (Phi√™n b·∫£n hi·ªán t·∫°i: {CURRENT_VERSION})")
    try:
        with urllib.request.urlopen(VERSION_URL, timeout=5) as response:
            data = json.loads(response.read().decode())
            latest_version = data.get("version")
            download_url = data.get("download_url")
            changelog = data.get("changelog", "")
        if latest_version and latest_version != CURRENT_VERSION:
            print(f"\nüöÄ PH√ÅT HI·ªÜN B·∫¢N C·∫¨P NH·∫¨T M·ªöI: {latest_version}")
            print(f"üìù N·ªôi dung thay ƒë·ªïi: {changelog}")
            choice = input("üëâ B·∫°n c√≥ mu·ªën c·∫≠p nh·∫≠t ngay kh√¥ng? (y/n): ").strip().lower()            
            if choice == 'y':
                print("‚è≥ ƒêang t·∫£i xu·ªëng b·∫£n m·ªõi...")
                current_exe = sys.executable
                new_exe = current_exe + ".new"
                urllib.request.urlretrieve(download_url, new_exe)
                print("‚úÖ T·∫£i xong! ƒêang c√†i ƒë·∫∑t...")
                batch_script = f"""
@echo off
timeout /t 2 /nobreak > NUL
del "{current_exe}"
move "{new_exe}" "{current_exe}"
start "" "{current_exe}"
del "%~f0"
"""
                batch_file = "update_tool.bat"
                with open(batch_file, "w") as f:
                    f.write(batch_script)
                subprocess.Popen(batch_file, shell=True)
                sys.exit(0)
        else:
            print("‚úÖ B·∫°n ƒëang d√πng phi√™n b·∫£n m·ªõi nh·∫•t.")
            time.sleep(1)
    except Exception as e:
        print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ ki·ªÉm tra c·∫≠p nh·∫≠t: {e}")
        print("   (B·ªè qua v√† ti·∫øp t·ª•c ch·∫°y ch∆∞∆°ng tr√¨nh...)")
        time.sleep(1)
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', line_buffering=True)
INDENT_STYLE = "\u3000\u3000" 
REPLACEMENT_CONFIG_FILE = "replacements.txt"
GARBAGE_CONFIG_FILE = "garbage.txt" 
def fast_print(*args, **kwargs):
    kwargs['flush'] = True
    print(*args, **kwargs)
def log_error(file_name, message):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    try:
        with open("processing_errors.log", "a", encoding="utf-8") as f:
            f.write(f"[{timestamp}] {file_name}: {message}\n")
    except: pass
def load_garbage_patterns():
    patterns = [
        r'https?://\S+', r'www\.\S+', r'\w+\.com', r'\w+\.net',
        r'S∆∞u t·∫ßm b·ªüi.*?', r'Ch√∫c b·∫°n ƒë·ªçc truy·ªán vui v·∫ª'
    ]
    if os.path.exists(GARBAGE_CONFIG_FILE):
        try:
            with open(GARBAGE_CONFIG_FILE, 'r', encoding='utf-8-sig') as f:
                for line in f:
                    if line.strip(): patterns.append(line.strip())
        except: pass
    return patterns
def clean_garbage_text(text, patterns=None):
    if patterns is None:
        patterns = load_garbage_patterns()
    for pattern in patterns:
        try:
            text = re.sub(pattern, '', text, flags=re.IGNORECASE)
        except: pass
    return text
def normalize_punctuation(text):
    text = re.sub(r'\s+([,.:;?!])', r'\1', text)
    text = re.sub(r'([,.:;?!])(?=[^\s\d])', r'\1 ', text)
    text = re.sub(r' +', ' ', text)
    return text
def load_replacements():
    replace_dict = {}
    if os.path.exists(REPLACEMENT_CONFIG_FILE):
        try:
            with open(REPLACEMENT_CONFIG_FILE, 'r', encoding='utf-8-sig') as f:
                for line in f:
                    if '=' in line:
                        parts = line.strip().split('=')
                        if len(parts) >= 2:
                            replace_dict[parts[0].strip()] = parts[1].strip()
        except: pass
    return replace_dict
def cn_to_int(cn_str):
    cn_map = {
        '„Äá': 0, 'Èõ∂': 0, '‰∏Ä': 1, '‰∫å': 2, '‰∏â': 3, 'Âõõ': 4, '‰∫î': 5, 
        'ÂÖ≠': 6, '‰∏É': 7, 'ÂÖ´': 8, '‰πù': 9, 'ÂçÅ': 10, 'Áôæ': 100, 'ÂçÉ': 1000, '‰∏á': 10000,
        '0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9
    }    
    if not cn_str: return 0
    if str(cn_str).isdigit(): return int(cn_str)
    result = 0
    temp = 0
    temp_unit = 1    
    try:
        for char in str(cn_str):
            if char in cn_map:
                val = cn_map[char]
                if val >= 10:
                    if val > temp_unit:
                        temp_unit = val
                        if temp == 0: temp = 1
                        result += temp * val
                        temp = 0
                    else:
                        temp_unit = val
                        result += val
                else:
                    temp = val
        result += temp
        return result
    except: return 0
def sanitize_filename(name):
    clean = re.sub(r'[\\/*?:"<>|]', "", name).strip()
    return clean[:100]
def clean_common_entities(text):
    text = html.unescape(text)
    text = text.replace("&nbsp;", " ")
    return text
def apply_replacements(text, replace_dict):
    for old, new in replace_dict.items():
        text = text.replace(old, new)
    return text
def clean_chapter_title(line, current_index):
    final_text = line.strip()
    final_text = clean_common_entities(final_text)    
    pattern = r'^(Áï™Â§ñ|Á¨¨\s*[0-9‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅÁôæÂçÉ‰∏á\s]+\s*[Á´†Âç∑]|Quy·ªÉn\s*[0-9‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅÁôæÂçÉ‰∏á\d]+|Ch∆∞∆°ng\s*\d+|Chapter\s*\d+|H·ªìi\s*\d+|ÂàÜÂç∑ÈòÖËØª\s*\d*|^\d+[\s\.\-„ÄÅ]*)'                 
    text = final_text
    if len(final_text) > 3 and not final_text.isdigit():
        text = re.sub(pattern, '', final_text, flags=re.IGNORECASE)        
    text = text.strip(" -=‚Äî‚Äì‚îÄ_*„ÄÄÔºö:,Ôºå.„ÄÅ")        
    if "Áï™Â§ñ" in final_text and "Áï™Â§ñ" not in text:
        text = "Áï™Â§ñ " + text       
    return text if text else f"Á¨¨{current_index}Á´†"
def check_sequence_gaps(raw_chapter_titles):
    print(f"\n{'*'*20} KI·ªÇM TRA L·ªñI ƒê√ÅNH S·ªê C·ª¶A T√ÅC GI·∫¢ {'*'*20}")
    last_num = None
    has_gap = False   
    num_pattern = re.compile(r'(?:Á¨¨\s*([0-9‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅÁôæÂçÉ‰∏á]+)\s*[Á´†Âõû]|Ch∆∞∆°ng\s*(\d+)|^\s*(\d+))', re.IGNORECASE)
    for raw_title in raw_chapter_titles:
        match = num_pattern.search(raw_title)
        if match:
            val_str = match.group(1) or match.group(2) or match.group(3)
            current_num = cn_to_int(val_str)            
            if last_num is not None:
                if current_num > last_num + 1:
                    print(f"‚ùå PH√ÅT HI·ªÜN THI·∫æU CH∆Ø∆†NG: T√°c gi·∫£ vi·∫øt t·ª´ [{last_num}] nh·∫£y v·ªçt l√™n [{current_num}]")
                    print(f"   -> D√≤ng l·ªói trong file: \"{raw_title}\"")
                    has_gap = True
                elif current_num < last_num:
                    print(f"‚ö†Ô∏è C·∫¢NH B√ÅO: S·ªë ch∆∞∆°ng b·ªã l√πi ho·∫∑c tr√πng: [{last_num}] xu·ªëng [{current_num}]")
                    print(f"   -> D√≤ng nghi v·∫•n: \"{raw_title}\"")
                    has_gap = True            
            last_num = current_num            
    if not has_gap:
        print("‚úÖ Ch√∫c m·ª´ng: T√°c gi·∫£ c·ªßa b·ª£n ƒë√°nh s·ªë ch∆∞∆°ng chu·∫©n vl, kh√¥ng th·∫•y ƒë·ª©t ƒëo·∫°n.")
    else:
        print(f"\n‚ùó L∆∞u √Ω: B·∫°n n√™n ki·ªÉm tra l·∫°i file g·ªëc t·∫°i c√°c v·ªã tr√≠ b√°o l·ªói tr√™n.")
    print(f"{'*'*65}\n")
def interactive_check_chapters(chapters, is_silent=False):
    print(f"\n{'='*20} R√Ä SO√ÅT CH∆Ø∆†NG NG·∫ÆN/L·ªñI {'='*20}")
    refined_chapters = []
    i = 0    
    history_stack = [] 
    while i < len(chapters):
        current_title, current_lines = chapters[i]
        content_text = "".join(map(str, current_lines[1:]))
        char_count = len(content_text.strip())        
        is_short_chapter = (i > 0 and char_count < 200)        
        if is_short_chapter:
            if is_silent:
                if char_count < 50:
                    if refined_chapters:
                        prev_title, prev_lines = refined_chapters[-1]
                        prev_lines.extend(current_lines)
                        print(f"ü§ñ [Auto] G·ªôp ch∆∞∆°ng si√™u ng·∫Øn '{current_title}' ({char_count} chars) v√†o ch∆∞∆°ng tr∆∞·ªõc.")
                    else:
                        refined_chapters.append((current_title, current_lines))
                else:
                    refined_chapters.append((current_title, current_lines))
                    print(f"ü§ñ [Auto] Gi·ªØ ch∆∞∆°ng ng·∫Øn '{current_title}' ({char_count} chars).")
                i += 1
            else:
                current_state_snapshot = [
                    (t, list(l)) for t, l in refined_chapters
                ]                
                print(f"{'!'*10} PH√ÅT HI·ªÜN CH∆Ø∆†NG NGHI V·∫§N {'!'*10}")
                print(f"üîñ Ti√™u ƒë·ªÅ: {current_title}") 
                print(f"üìâ ƒê·ªô d√†i: {char_count} k√Ω t·ª±")
                print(f"üìÑ Tr√≠ch ƒëo·∫°n:\n{'-'*30}")
                print('\n'.join([str(l).strip() for l in current_lines[:6] if str(l).strip()]))
                print(f"{'-'*30}")            
                print("üëâ Ch·ªçn c√°ch x·ª≠ l√Ω:")
                print("   [1] G·ªòP v√†o ch∆∞∆°ng tr∆∞·ªõc (Gi·ªØ nguy√™n to√†n b·ªô n·ªôi dung)")
                print("   [2] GI·ªÆ NGUY√äN (ƒê·ªÉ th√†nh ch∆∞∆°ng ri√™ng)")
                print("   [3] X√ìA B·ªé (N·∫øu l√† r√°c)")
                print("   [b] QUAY L·∫†I (Undo quy·∫øt ƒë·ªãnh tr∆∞·ªõc ƒë√≥)")                
                choice = input("   Nh·∫≠p l·ª±a ch·ªçn (Enter=1, b=Back): ").strip()                
                if choice.lower() == 'b':
                    if not history_stack:
                        print("‚ö†Ô∏è Kh√¥ng th·ªÉ quay l·∫°i xa h∆°n (ƒê√¢y l√† ch∆∞∆°ng ƒë·∫ßu ti√™n ho·∫∑c ch∆∞a c√≥ l·ªãch s·ª≠)!")
                        continue 
                    else:
                        last_i, last_refined_chapters = history_stack.pop()
                        i = last_i
                        refined_chapters = last_refined_chapters
                        print("‚è™ ƒê√£ quay l·∫°i quy·∫øt ƒë·ªãnh tr∆∞·ªõc ƒë√≥.")
                        continue
                history_stack.append((i, current_state_snapshot))
                if choice == '2':
                    refined_chapters.append((current_title, current_lines))
                elif choice == '3':
                    print("üóëÔ∏è ƒê√£ x√≥a.\n")
                else:
                    if refined_chapters:
                        prev_title, prev_lines = refined_chapters[-1]
                        prev_lines.extend(current_lines) 
                        print(f"üîó ƒê√£ g·ªôp th√†nh c√¥ng.\n")
                    else:
                        refined_chapters.append((current_title, current_lines))                
                i += 1
        else:
            refined_chapters.append((current_title, current_lines))
            i += 1            
    return refined_chapters
def verify_and_report_final(output_dir, chapters_with_notes):
    if not os.path.exists(output_dir): return
    files = [f for f in os.listdir(output_dir) if f.endswith(".txt")]            
    def get_sort_key(filename):
        match_chapter = re.search(r'(?:Ch∆∞∆°ng|Chapter|Á¨¨|H·ªìi)\s*(\d+)', filename, re.IGNORECASE)
        if match_chapter:
            return int(match_chapter.group(1))
        nums = re.findall(r'\d+', filename)
        return int(nums[0]) if nums else 0            
    files.sort(key=get_sort_key)
    safe_notes = {sanitize_filename(name) for name in chapters_with_notes}
    print(f"\n{'STT':<5} {'DUNG L∆Ø·ª¢NG':<12} {'[TG]':<6} {'T√äN FILE'}")
    print("-" * 80)    
    for idx, f in enumerate(files):
        size = os.path.getsize(os.path.join(output_dir, f))
        file_name_no_ext = os.path.splitext(f)[0]
        has_note = "[v]" if file_name_no_ext in safe_notes else ""
        print(f"{idx+1:<5} {size:<12} {has_note:<6} {f}")
def create_epub_file(output_path, book_title, chapters, author="Unknown", cover_path=None):
    """T·∫°o file EPUB t·ª´ danh s√°ch ch∆∞∆°ng m√† kh√¥ng c·∫ßn th∆∞ vi·ªán ngo√†i"""
    print(f"üìö ƒêang ƒë√≥ng g√≥i EPUB: {output_path} ...")    
    try:
        with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as z:
            z.writestr("mimetype", "application/epub+zip", zipfile.ZIP_STORED)           
            container_xml = '''<?xml version="1.0" encoding="UTF-8"?>
<container version="1.0" xmlns="urn:oasis:names:tc:opendocument:xmlns:container">
    <rootfiles>
        <rootfile full-path="OEBPS/content.opf" media-type="application/oebps-package+xml"/>
    </rootfiles>
</container>'''
            z.writestr("META-INF/container.xml", container_xml)            
            manifest_items = []
            spine_refs = []
            nav_points = []            
            css_content = '''body { font-family: "Times New Roman", serif; line-height: 1.5; margin: 5%; }
h2 { text-align: center; color: #333; page-break-after: avoid; }
p { text-indent: 2em; margin-bottom: 0.5em; text-align: justify; }
.cover { text-align: center; height: 100%; }
.cover img { max-width: 100%; max-height: 100%; }'''
            z.writestr("OEBPS/style.css", css_content)
            manifest_items.append('<item id="style" href="style.css" media-type="text/css"/>')
            cover_meta = ""
            if cover_path and os.path.exists(cover_path):
                ext = os.path.splitext(cover_path)[1].lower().replace('.', '')
                media_type = "image/jpeg" if ext in ['jpg', 'jpeg'] else "image/png"
                z.write(cover_path, f"OEBPS/cover.{ext}")
                manifest_items.append(f'<item id="cover-image" href="cover.{ext}" media-type="{media_type}"/>')
                cover_meta = '<meta name="cover" content="cover-image"/>'
                cover_html = f'''<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head><title>Cover</title><link href="style.css" rel="stylesheet" type="text/css"/></head>
<body><div class="cover"><img src="cover.{ext}" alt="Cover"/></div></body></html>'''
                z.writestr("OEBPS/cover.html", cover_html)
                manifest_items.append('<item id="cover-page" href="cover.html" media-type="application/xhtml+xml"/>')
                spine_refs.append('<itemref idref="cover-page"/>')
            for idx, (title, lines) in enumerate(chapters):
                file_name = f"chapter_{idx+1}.html"
                html_body = []
                html_body.append(f'<h2>{html.escape(title)}</h2>')
                for line in lines:
                    if not line.strip(): continue
                    clean_line = line.strip().lstrip("„ÄÄ \t")
                    html_body.append(f'<p>{html.escape(clean_line)}</p>')                
                html_content = f'''<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head><title>{html.escape(title)}</title><link href="style.css" rel="stylesheet" type="text/css"/></head>
<body>
{"".join(html_body)}
</body></html>'''                
                z.writestr(f"OEBPS/{file_name}", html_content)               
                item_id = f"chap{idx+1}"
                manifest_items.append(f'<item id="{item_id}" href="{file_name}" media-type="application/xhtml+xml"/>')
                spine_refs.append(f'<itemref idref="{item_id}"/>')
                nav_points.append(f'<navPoint id="nav{idx+1}" playOrder="{idx+1}"><navLabel><text>{html.escape(title)}</text></navLabel><content src="{file_name}"/></navPoint>')            
            opf_content = f'''<?xml version="1.0" encoding="UTF-8"?>
<package xmlns="http://www.idpf.org/2007/opf" unique-identifier="BookID" version="2.0">
    <metadata xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:opf="http://www.idpf.org/2007/opf">
        <dc:title>{html.escape(book_title)}</dc:title>
        <dc:creator>{author}</dc:creator>
        <dc:language>vi</dc:language>
        <dc:identifier id="BookID" opf:scheme="UUID">{uuid.uuid4()}</dc:identifier>
        {cover_meta}
    </metadata>
    <manifest>
        <item id="ncx" href="toc.ncx" media-type="application/x-dtbncx+xml"/>
        {"".join(manifest_items)}
    </manifest>
    <spine toc="ncx">
        {"".join(spine_refs)}
    </spine>
</package>'''
            z.writestr("OEBPS/content.opf", opf_content)
            ncx_content = f'''<?xml version="1.0" encoding="UTF-8"?>
<ncx xmlns="http://www.daisy.org/z3986/2005/ncx/" version="2005-1">
    <head>
        <meta name="dtb:uid" content="{uuid.uuid4()}"/>
        <meta name="dtb:depth" content="1"/>
        <meta name="dtb:totalPageCount" content="0"/>
        <meta name="dtb:maxPageNumber" content="0"/>
    </head>
    <docTitle><text>{book_title}</text></docTitle>
    <navMap>
        {"".join(nav_points)}
    </navMap>
</ncx>'''
            z.writestr("OEBPS/toc.ncx", ncx_content)            
        print("‚úÖ ƒê√£ t·∫°o EPUB th√†nh c√¥ng!")
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫°o EPUB: {e}")
        log_error(book_title, f"L·ªói t·∫°o EPUB: {e}")
def split_and_format_v6_reindex(input_file, start_chapter_num=1, signature_text="", 
                                output_mode="split", is_silent=False, indent_str="\u3000\u3000", keep_original_numbering=False):
    base_name = os.path.splitext(os.path.basename(input_file))[0]
    output_dir = ""    
    replacements = load_replacements()    
    garbage_patterns = load_garbage_patterns() 
    if output_mode == "split":
        output_dir = os.path.join(os.path.dirname(input_file), f"{base_name}_Split")
        if not os.path.exists(output_dir): os.makedirs(output_dir)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
    lines = []    
    file_size = os.path.getsize(input_file)
    limit = 10 * 1024 * 1024    
    encodings = ['utf-8-sig', 'utf-16', 'gb18030', 'utf-8']    
    for enc in encodings:
        try:
            if file_size < limit:
                if not is_silent: print(f"üìñ ƒêang n·∫°p d·ªØ li·ªáu v√† x·ª≠ l√Ω thay th·∫ø t·ª´ ƒëi·ªÉn...", end='', flush=True)
                with open(input_file, 'r', encoding=enc) as f:
                    full_text = f.read()
                    full_text = clean_common_entities(full_text)
                    full_text = apply_replacements(full_text, replacements)
                    lines = full_text.splitlines()
                if not is_silent: print(" Ho√†n t·∫•t!", flush=True)
            else:
                if not is_silent: print(f"File l·ªõn ({file_size/1024/1024:.1f}MB), d√πng ch·∫ø ƒë·ªô ƒë·ªçc t·ª´ng d√≤ng ƒë·ªÉ ti·∫øt ki·ªám RAM...")
                with open(input_file, 'r', encoding=enc) as f:
                    for line in f:
                        l = clean_common_entities(line)
                        l = apply_replacements(l, replacements)
                        lines.append(l.rstrip('\n'))
            if lines: break
        except: continue                                   
    if not lines: 
        print(f"‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file: {input_file}")
        log_error(base_name, "Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file ho·∫∑c file tr·ªëng.")
        return        
    re_eq_sep = re.compile(r'^\s*={10,}\s*$')
    re_dash_long = re.compile(r'^\s*-{40,}\s*$')    
    re_note_for_equals_mode = re.compile(r'^\s*(-{20,})\s*$')
    re_note_for_dash_mode = re.compile(r'^\s*([_*]{5,}|[‚Äî‚Äì‚îÄ]{7,})\s*$')
    re_note_default = re.compile(r'^\s*([_*]{5,}|-{6,39}|[‚Äî‚Äì‚îÄ]{7,})\s*$')
    note_keywords = ["‰ΩúËÄÖÊúâËØùËØ¥", "ÂèëË°®‰∫é", "Â∞èÂâßÂú∫", "Ê±ÇÊúàÁ•®", "Ê±ÇÊî∂Ëóè", "PS:", "ps:"]
    re_susuinian_strict = re.compile(r'^(\[.*?\]|Ôºà.*?Ôºâ)?Á¢éÁ¢éÂøµ[:Ôºö]\s*$')                                                 
    eq_count = sum(1 for l in lines if re_eq_sep.match(l))
    dash_long_count = sum(1 for l in lines if re_dash_long.match(l))    
    if eq_count > dash_long_count and eq_count > 2:
        mode = "PRIORITY_EQUALS"
    elif dash_long_count >= eq_count and dash_long_count > 2:
        mode = "PRIORITY_DASH_LONG"
    else:
        mode = "FALLBACK_KEYWORDS"           
    if not is_silent: print(f"[{base_name}] Th·ªëng k√™: [=]: {eq_count} | [-]: {dash_long_count} -> MODE: {mode}")    
    chapters = []
    raw_titles_for_check = []
    current_title = "Ph·∫ßn m·ªü ƒë·∫ßu"
    current_lines = []
    temp_idx = start_chapter_num 
    i = 0
    total_lines = len(lines)
    decision_history = []     
    while i < total_lines:
        line = lines[i].strip()
        raw_line = lines[i]
        is_new_chapter = False
        raw_title = ""
        jump_to = i                
        found_sep = False
        if re_eq_sep.match(raw_line): found_sep = True
        elif mode == "PRIORITY_EQUALS" and re_eq_sep.match(line): found_sep = True
        elif mode == "PRIORITY_DASH_LONG" and re_dash_long.match(line): found_sep = True
        if found_sep:
            check_directions = ["DOWN", "UP"] if mode == "PRIORITY_DASH_LONG" else ["UP", "DOWN"]            
            for direction in check_directions:
                if is_new_chapter: break
                if direction == "UP":
                    k = i - 1
                    while k >= 0 and not lines[k].strip():
                        k -= 1
                    if k >= 0:
                        prev_line = lines[k].strip()
                        if len(prev_line) < 150:
                            if current_lines and current_lines[-1].strip() == prev_line:
                                raw_title = current_lines.pop()
                                is_new_chapter = True
                                jump_to = i                 
                elif direction == "DOWN":
                    next_idx = i + 1
                    while next_idx < total_lines and not lines[next_idx].strip(): next_idx += 1
                    if next_idx < total_lines:
                        raw_title = lines[next_idx].strip()
                        if len(raw_title) > 80:
                            is_new_chapter = False
                        else:
                            is_new_chapter = True
                            jump_to = next_idx
                    else:
                        break
        if not is_new_chapter:
            re_explicit = re.compile(r'^\s*(Áï™Â§ñ|Á¨¨\s*[0-9‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅÁôæÂçÉ‰∏á]+\s*[Á´†Âç∑]|Quy·ªÉn\s*[0-9‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅÁôæÂçÉ‰∏á\d]+|Ch∆∞∆°ng\s*\d+|Chapter\s*\d+|H·ªìi\s*\d+|^\d+[.,„ÄÅ\s]+|^\d+$)', re.IGNORECASE)            
            is_digit_dot_title = re.match(r'^\d+[\.,]{2,}', line) 
            if (re_explicit.match(line) or is_digit_dot_title) and len(line) < 150:
                next_is_sep = False                
                k = i + 1
                while k < total_lines and not lines[k].strip():
                    k += 1               
                if k < total_lines:
                    l_next = lines[k].strip()
                    if mode == "PRIORITY_EQUALS" and re_eq_sep.match(l_next): 
                        next_is_sep = True
                    elif mode == "PRIORITY_DASH_LONG" and re_dash_long.match(l_next): 
                        next_is_sep = True                
                if next_is_sep:
                    is_new_chapter = True
                    raw_title = line
                    jump_to = k 
                else:
                    is_digit_start = re.match(r'^\d+', line)
                    should_ask = (mode in ["PRIORITY_EQUALS", "PRIORITY_DASH_LONG"]) or (is_digit_start and not is_digit_dot_title)                    
                    if is_digit_dot_title: should_ask = False
                    if should_ask:
                        if is_silent:
                            if is_digit_start and re.search(r'^\d+[„ÄÅ\.,]\s*\d+[„ÄÅ\.,]', line):
                                 is_new_chapter = False
                            elif is_digit_start and len(line) < 4: 
                                 is_new_chapter = False
                            else:
                                 is_new_chapter = True
                                 raw_title = line
                                 jump_to = i
                        else:
                            snapshot = (i, list(chapters), current_title, list(current_lines), temp_idx, list(raw_titles_for_check))
                            do_rollback = False
                            while True:
                                reason = "S·ªê ƒê·∫¶U D√íNG (D·ªÖ nh·∫ßm li·ªát k√™)" if is_digit_start else f"MODE {mode}"
                                print(f"\n{'?'*10} PH√ÅT HI·ªÜN NGHI V·∫§N [{reason}] {'?'*10}")
                                print(f"üìå D√≤ng: {line}")
                                print("üëâ L·ª±a ch·ªçn:")
                                print("   [1] T√ÅCH CH∆Ø∆†NG (ƒê√¢y l√† ti√™u ƒë·ªÅ)")
                                print("   [2] B·ªé QUA (ƒê√¢y l√† n·ªôi dung/ƒë·∫øm ng∆∞·ª£c/li·ªát k√™)")
                                print("   [b] QUAY L·∫†I (Undo quy·∫øt ƒë·ªãnh tr∆∞·ªõc ƒë√≥)")
                                choice = input("   Nh·∫≠p (Enter=2, b=Back): ").strip()                               
                                if choice.lower() == 'b':
                                    if not decision_history:
                                        print("‚ö†Ô∏è Kh√¥ng th·ªÉ quay l·∫°i xa h∆°n!")
                                        continue
                                    else:
                                        (i, chapters, current_title, current_lines, temp_idx, raw_titles_for_check) = decision_history.pop()
                                        do_rollback = True
                                        print("‚è™ ƒê√£ quay l·∫°i ƒëi·ªÉm quy·∫øt ƒë·ªãnh tr∆∞·ªõc ƒë√≥!")
                                        break
                                if choice == '1':
                                    is_new_chapter = True
                                    raw_title = line
                                    jump_to = i
                                    decision_history.append(snapshot)
                                    break
                                elif choice == '2' or choice == '':
                                    is_new_chapter = False
                                    decision_history.append(snapshot)
                                    break                        
                            if do_rollback:
                                continue
                    else:
                        is_new_chapter = True
                        raw_title = line
                        jump_to = i                       
        if is_new_chapter:
            if len(raw_title) > 30:
                if is_silent:
                    if len(raw_title) < 100:
                        i = jump_to
                    else:
                        is_new_chapter = False
                else:
                    snapshot = (i, list(chapters), current_title, list(current_lines), temp_idx, list(raw_titles_for_check))
                    do_rollback = False                    
                    while True:
                        print(f"\n{'!'*10} C·∫¢NH B√ÅO TI√äU ƒê·ªÄ D√ÄI ({len(raw_title)} k√Ω t·ª±) {'!'*10}")
                        print(f"üîé N·ªôi dung: {raw_title}")
                        print("üëâ L·ª±a ch·ªçn:")
                        print("   [1] CH·∫§P NH·∫¨N t√°ch ch∆∞∆°ng (ƒê√¢y l√† ti√™u ƒë·ªÅ)")
                        print("   [2] B·ªé QUA v√† g·ªôp (ƒê√¢y l√† n·ªôi dung vƒÉn b·∫£n)")
                        print("   [b] QUAY L·∫†I (Undo quy·∫øt ƒë·ªãnh tr∆∞·ªõc ƒë√≥)")
                        choice = input("   Nh·∫≠p (Enter=1, b=Back): ").strip()                        
                        if choice.lower() == 'b':
                            if not decision_history:
                                print("‚ö†Ô∏è Kh√¥ng th·ªÉ quay l·∫°i xa h∆°n!")
                                continue
                            else:
                                (i, chapters, current_title, current_lines, temp_idx, raw_titles_for_check) = decision_history.pop()
                                do_rollback = True
                                print("‚è™ ƒê√£ quay l·∫°i ƒëi·ªÉm quy·∫øt ƒë·ªãnh tr∆∞·ªõc ƒë√≥!")
                                break
                        if choice == '2':
                            is_new_chapter = False
                            decision_history.append(snapshot)
                            break
                        else:
                            i = jump_to
                            decision_history.append(snapshot)
                            break                            
                    if do_rollback:
                        continue
            else:
                i = jump_to                        
        if is_new_chapter:
            raw_titles_for_check.append(raw_title)
            potential_clean_title = clean_chapter_title(raw_title, temp_idx)            
            if current_lines: 
                chapters.append((current_title, current_lines))            
            current_title = potential_clean_title            
            current_lines = [raw_title]            
            temp_idx += 1
        else:
            if line:
                cleaned = clean_garbage_text(line, garbage_patterns)
                cleaned = normalize_punctuation(cleaned)
                current_lines.append(cleaned)
        i += 1           
    if current_lines: chapters.append((current_title, current_lines))   
    if not is_silent: check_sequence_gaps(raw_titles_for_check)
    chapters = interactive_check_chapters(chapters, is_silent)                    
    final_processed_chapters = []
    current_idx = start_chapter_num    
    total_chars = 0
    chapters_with_notes = []           
    for idx, (raw_name, content) in enumerate(chapters):
        if not content: continue                      
        while len(content) > 1:
            last_line = content[-1].strip()
            if re_note_default.match(last_line) or re_note_for_equals_mode.match(last_line) or re_note_for_dash_mode.match(last_line) or not last_line:
                content.pop()
            else:
                break               
        new_content = [content[0]]
        body_lines = content[1:]
        split_point = -1
        last_sep_pos = -1 
        note_found_in_this_chapter = False                                              
        search_range = range(len(body_lines)-1, max(-1, len(body_lines)-20), -1)                
        for j in search_range:
            l = body_lines[j].strip()
            if not l: continue                    
            is_kw_normal = any(l.startswith(kw) for kw in note_keywords)
            is_kw_strict = bool(re_susuinian_strict.match(l)) and len(l) <= 10            
            is_kw = is_kw_normal or is_kw_strict                        
            if mode == "PRIORITY_DASH_LONG":
                is_sep = False
            else:
                is_sep = (re_note_for_equals_mode.match(l) or 
                          re_note_for_dash_mode.match(l) or 
                          re_note_default.match(l))
                if is_sep and len(l) > 25: is_sep = False                                  
            if is_kw:
                split_point = j
                note_found_in_this_chapter = True
                break
            elif is_sep and split_point == -1:
                has_content_below = any(body_lines[k].strip() for k in range(j + 1, len(body_lines)))
                if has_content_below:
                    last_sep_pos = j
                    note_found_in_this_chapter = True                
        if split_point == -1:
            split_point = last_sep_pos                    
        for k, line in enumerate(body_lines):
            l_strip = line.strip()
            if not l_strip: continue                        
            if k == split_point:
                new_content.append(f"\n{indent_str}„Äê‰ΩúËÄÖÊúâËØùËØ¥„Äë")
                is_pure_sep = (re_note_for_equals_mode.match(l_strip) or re_note_for_dash_mode.match(l_strip) or re_note_default.match(l_strip))
                if not is_pure_sep:
                    clean_l = re.sub(r'^(‰ΩúËÄÖÊúâËØùËØ¥|ÂèëË°®‰∫é|Â∞èÂâßÂú∫|Ê±ÇÊúàÁ•®|Ê±ÇÊî∂Ëóè|PS:|ps:|.*Á¢éÁ¢éÂøµ[:Ôºö])', '', l_strip).strip("Ôºö: -=")
                    if clean_l: new_content.append(f"{indent_str}" + clean_l)
            else:
                new_content.append(f"{indent_str}" + l_strip)        
        raw_name = raw_name.strip()
        prefix_pattern = r'^(Á¨¨\s*[0-9‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅÁôæÂçÉ‰∏á\s]+\s*[Á´†ÂõûÂç∑]|Quy·ªÉn\s*[0-9‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅÁôæÂçÉ‰∏á\d]+|Ch∆∞∆°ng\s*\d+|Chapter\s*\d+|H·ªìi\s*\d+|ÂàÜÂç∑ÈòÖËØª\s*\d*|\d+[\s\.\-„ÄÅ]+)'
        if idx == 0 and any(k in raw_name.lower() for k in ["m·ªü ƒë·∫ßu", "vƒÉn √°n"]):
            new_title_str = raw_name
        else:
            original_title_line = content[0].strip()           
            clean_text = re.sub(prefix_pattern, '', original_title_line, flags=re.IGNORECASE).strip()
            clean_text = re.sub(prefix_pattern, '', clean_text, flags=re.IGNORECASE).strip()
            clean_text = clean_text.strip(" -=‚Äî‚Äì‚îÄ_*„ÄÄÔºö:,Ôºå.„ÄÅ")            
            is_fanwai = False
            if "Áï™Â§ñ" in original_title_line or "fanwai" in original_title_line.lower():
                is_fanwai = True
                if "Áï™Â§ñ" not in clean_text:
                    clean_text = "Áï™Â§ñ " + clean_text
            if keep_original_numbering:
                real_num = -1                
                match_arab = re.search(r'(?:Á¨¨|Ch∆∞∆°ng|Chapter|Chap|H·ªìi|Part|Vol|Quy·ªÉn)?\s*([0-9]+)\s*[.:\-Á´†ÂõûÂç∑\s]', original_title_line, re.IGNORECASE)
                if match_arab:
                    real_num = int(match_arab.group(1))
                elif not match_arab:
                    match_cn = re.search(r'Á¨¨\s*([Èõ∂‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅÁôæÂçÉ‰∏á]+)\s*[Á´†ÂõûÂç∑]', original_title_line)
                    if match_cn:
                        real_num = cn_to_int(match_cn.group(1))
                if real_num > 0:
                    if is_fanwai and real_num < current_idx:
                        pass 
                    else:
                        current_idx = real_num           
            new_title_str = f"Á¨¨{current_idx}Á´† {clean_text}"            
            current_idx += 1                                                                         
        if note_found_in_this_chapter:
            chapters_with_notes.append(new_title_str)                                                                          
        total_chars += len("".join(map(str, new_content[1:])).strip())
        new_content[0] = new_title_str       
        if signature_text: new_content.append("\n" + signature_text)        
        final_processed_chapters.append((new_title_str, new_content))   
    if not is_silent: print(f"\n‚ö° ƒêang xu·∫•t file d∆∞·ªõi d·∫°ng: {output_mode.upper()}...")   
    if output_mode == "split":
        count = 0
        for title, content in final_processed_chapters:
            safe_name = sanitize_filename(title)            
            try:
                with open(os.path.join(output_dir, f"{safe_name}.txt"), 'w', encoding='utf-8-sig') as f:
                    f.write('\n'.join(map(str, content)))
                count += 1
            except Exception as e:
                log_error(base_name, f"L·ªói ghi ch∆∞∆°ng {title}: {e}")
        if not is_silent:
            print(f"\n" + " T·ªîNG K·∫æT D·ªÆ LI·ªÜU ".center(60, "="))
            print(f"üìä T·ªïng s·ªë ch∆∞∆°ng: {count}")
            print(f"üìù T·ªïng k√Ω t·ª± n·ªôi dung: {total_chars:,}")
            print(f"üìÇ Th∆∞ m·ª•c: {output_dir}")
            print(f"üí° Ch√∫ th√≠ch: [v] = Ch∆∞∆°ng c√≥ l·ªùi t√°c gi·∫£")
            verify_and_report_final(output_dir, chapters_with_notes)            
    elif output_mode == "merge":
        out_file = os.path.join(os.path.dirname(input_file), f"{base_name}_cleaned.txt")
        try:
            with open(out_file, 'w', encoding='utf-8-sig') as f:
                f.write('\n\n'.join(['\n'.join(map(str, c)) for t, c in final_processed_chapters]))
            print(f"‚úÖ ƒê√£ g·ªôp file: {out_file}")
        except Exception as e:
            log_error(base_name, f"L·ªói ghi file merge: {e}") 
    elif output_mode == "epub":
        out_file = os.path.join(os.path.dirname(input_file), f"{base_name}.epub")
        epub_chapters = []
        for t, c in final_processed_chapters:
            epub_chapters.append((t, c[1:]))
        cover_path = None
        input_dir = os.path.dirname(input_file)
        possible_names = ["cover.jpg", "cover.png", f"{base_name}.jpg", f"{base_name}.png"]
        for p in possible_names:
            full_p = os.path.join(input_dir, p)
            if os.path.exists(full_p):
                cover_path = full_p
                print(f"üñºÔ∏è Ph√°t hi·ªán ·∫£nh b√¨a: {p}")
                break       
        create_epub_file(out_file, base_name, epub_chapters, cover_path=cover_path)
if __name__ == "__main__":
    check_for_updates()
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    CONFIG_FILE = os.path.join(BASE_DIR, "signature_config.txt")    
    if not os.path.exists(REPLACEMENT_CONFIG_FILE):
        with open(REPLACEMENT_CONFIG_FILE, 'w', encoding='utf-8-sig') as f:
            f.write("vietnam=Vi·ªát Nam\nkh·ª±a=Trung Qu·ªëc\n")
    if not os.path.exists(GARBAGE_CONFIG_FILE):
        with open(GARBAGE_CONFIG_FILE, 'w', encoding='utf-8-sig') as f:
             f.write("https://.*\nwww\\..*\n")
    def load_signature():
        if os.path.exists(CONFIG_FILE):
            try:
                with open(CONFIG_FILE, 'r', encoding='utf-8-sig') as f:
                    return f.read().strip()
            except: return ""
        return ""    
    def save_signature(text):
        try:
            with open(CONFIG_FILE, 'w', encoding='utf-8-sig') as f:
                f.write(text)
            return True
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói kh√¥ng th·ªÉ l∆∞u file ghi nh·ªõ: {e}")
            return False                
    while True:
        os.system('cls' if os.name == 'nt' else 'clear')
        print(" TOOL CLEAN RAW ".center(70, "="))
        print("üí° H·ªó tr·ª£: K√©o th·∫£ 1 File .txt HO·∫∂C 1 Th∆∞ m·ª•c (Batch Mode)")        
        try:
            path_input = input("üëâ ƒê∆∞·ªùng d·∫´n: ").strip('"').strip("'").strip()
            if path_input.lower() in ['q', 'exit']: break                                                                    
            target_files = []
            if os.path.isfile(path_input):
                target_files.append(path_input)
            elif os.path.isdir(path_input):
                print(f"üìÇ ƒê√£ ph√°t hi·ªán th∆∞ m·ª•c. ƒêang qu√©t file .txt...")
                for root, dirs, files in os.walk(path_input):
                    for file in files:
                        if file.lower().endswith(".txt") and "_Split" not in root:
                            target_files.append(os.path.join(root, file))
                print(f"üìä T√¨m th·∫•y {len(target_files)} file .txt")
            else:
                print("‚ùå ƒê∆∞·ªùng d·∫´n kh√¥ng t·ªìn t·∫°i.")
                input("Nh·∫•n Enter ƒë·ªÉ quay l·∫°i...")
                continue                
            if not target_files:
                input("‚ùå Kh√¥ng c√≥ file n√†o ƒë·ªÉ x·ª≠ l√Ω. Enter...")
                continue
            output_mode = "split"
            is_silent = False
            indent_str = "\u3000\u3000"
            keep_original = False
            start_num = 1
            sig = ""
            step = 1
            cancel_process = False            
            while step <= 6:
                os.system('cls' if os.name == 'nt' else 'clear')
                print(f"üìÇ ƒêang thi·∫øt l·∫≠p cho: {os.path.basename(path_input)}")
                print(f"‚ÑπÔ∏è  T√¨m th·∫•y: {len(target_files)} files")
                print("(üí° M·∫πo: Nh·∫≠p 'b' v√† Enter ƒë·ªÉ quay l·∫°i b∆∞·ªõc tr∆∞·ªõc)\n")
                if step == 1:
                    print("‚öôÔ∏è [1/6] C·∫§U H√åNH ƒê·ªäNH D·∫†NG:")
                    print("1. Xu·∫•t ra Folder t·ª´ng ch∆∞∆°ng (Split)")
                    print("2. Xu·∫•t ra 1 File g·ªôp (Merge Txt)")
                    print("3. Xu·∫•t ra Ebook (EPUB)")
                    out_choice = input("üëâ Ch·ªçn ƒë·ªãnh d·∫°ng (Enter=1): ").strip()
                    if out_choice.lower() == 'b': 
                        cancel_process = True
                        break                    
                    output_mode = "split"
                    if out_choice == '2': output_mode = "merge"
                    elif out_choice == '3': output_mode = "epub"
                    step += 1
                elif step == 2:
                    print(f"ü§ñ [2/6] CH·∫æ ƒê·ªò T·ª∞ ƒê·ªòNG (SILENT MODE)?")
                    print("   [y] C√≥ (T·ª± s·ª≠a l·ªói, kh√¥ng h·ªèi, th√≠ch h·ª£p treo m√°y)")
                    print("   [n] Kh√¥ng (D·ª´ng l·∫°i h·ªèi khi g·∫∑p l·ªói - An to√†n h∆°n)")
                    silent_input = input("üëâ Ch·ªçn (y/n, Enter=n): ").lower().strip()
                    if silent_input == 'b':
                        step = 1
                        continue
                    is_silent = (silent_input == 'y')
                    step += 1
                elif step == 3:
                    print("\nüìù [3/6] KI·ªÇU TH·ª§T ƒê·∫¶U D√íNG:")
                    print("   [1] Chu·∫©n Trung (2 k√Ω t·ª± „ÄÄ„ÄÄ)")
                    print("   [2] Chu·∫©n Vi·ªát (1 Tab)")
                    print("   [3] 4 D·∫•u c√°ch") 
                    indent_choice = input("üëâ Ch·ªçn (Enter=1): ").strip()
                    if indent_choice.lower() == 'b':
                        step = 2
                        continue
                    indent_str = "\u3000\u3000"
                    if indent_choice == '2': indent_str = "\t"
                    elif indent_choice == '3': indent_str = "    "
                    step += 1
                elif step == 4:
                    print("\nüî¢ [4/6] CH·∫æ ƒê·ªò ƒê√ÅNH S·ªê CH∆Ø∆†NG:")
                    print("   [1] T·ª± ƒë·ªông ƒë√°nh l·∫°i (1, 2, 3...) - N√™n d√πng n·∫øu file ƒë·∫ßy ƒë·ªß to√†n b·ªô t·ª´ 1 ƒë·∫øn h·∫øt")
                    print("   [2] Gi·ªØ nguy√™n s·ªë c·ªßa t√°c gi·∫£ (Theo file g·ªëc) - N√™n d√πng n·∫øu file l√† c√°c ch∆∞∆°ng kh√¥ng b·∫Øt ƒë·∫ßu t·ª´ 1")
                    num_mode_choice = input("üëâ Ch·ªçn (Enter=1): ").strip()
                    if num_mode_choice.lower() == 'b':
                        step = 3
                        continue
                    keep_original = (num_mode_choice == '2')
                    step += 1
                elif step == 5:
                    if len(target_files) > 1 or keep_original:
                        step += 1
                        continue                        
                    print("\nüî¢ [5/6] THI·∫æT L·∫¨P S·ªê CH∆Ø∆†NG:")
                    s_num = input("üëâ S·ªë ch∆∞∆°ng b·∫Øt ƒë·∫ßu (Enter=1): ").strip()
                    if s_num.lower() == 'b':
                        step = 4
                        continue
                    start_num = int(s_num) if s_num.isdigit() else 1
                    step += 1
                elif step == 6:
                    print("\n‚úçÔ∏è [6/6] CH·ªÆ K√ù CU·ªêI CH∆Ø∆†NG:")
                    saved_sig = load_signature()
                    sig = ""
                    if saved_sig:
                        print(f"‚≠ê Ch·ªØ k√Ω ƒëang nh·ªõ: {saved_sig}")
                        sig_input = input("üëâ Enter d√πng l·∫°i, nh·∫≠p m·ªõi ƒë·ªÉ ƒë·ªïi, 'x' x√≥a: ").strip()
                        if sig_input.lower() == 'b':
                            if len(target_files) > 1 or keep_original:
                                step = 4
                            else:
                                step = 5
                            continue                        
                        if sig_input == "": sig = saved_sig
                        elif sig_input.lower() == 'x': 
                            save_signature("")
                            print("‚úÖ ƒê√£ x√≥a ch·ªØ k√Ω.")
                        else: 
                            sig = sig_input
                            save_signature(sig)
                    else:
                        sig_input = input("üëâ Nh·∫≠p ch·ªØ k√Ω (Enter b·ªè qua): ").strip()
                        if sig_input.lower() == 'b':
                            if len(target_files) > 1 or keep_original:
                                step = 4
                            else:
                                step = 5
                            continue
                        if sig_input:
                            sig = sig_input
                            save_signature(sig)
                    step += 1            
            if cancel_process:
                continue
            print(f"\nüöÄ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù {len(target_files)} FILE...\n")
            if is_silent and len(target_files) > 1:
                print(f"‚ö° ƒêang ch·∫°y ch·∫ø ƒë·ªô ƒêA LU·ªíNG (Max 4 ti·∫øn tr√¨nh)...")
                with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
                    futures = []
                    for fpath in target_files:
                        futures.append(executor.submit(
                            split_and_format_v6_reindex,
                            input_file=fpath,
                            start_chapter_num=start_num,
                            signature_text=sig,
                            output_mode=output_mode,
                            is_silent=True,
                            indent_str=indent_str,
                            keep_original_numbering=keep_original
                        ))
                    for future in concurrent.futures.as_completed(futures):
                        try:
                            future.result()
                        except Exception as e:
                            print(f"‚ùå C√≥ l·ªói trong thread: {e}")
            else:
                for idx, fpath in enumerate(target_files):
                    print(f"‚è≥ [{idx+1}/{len(target_files)}] Processing: {os.path.basename(fpath)}...")
                    try:
                        split_and_format_v6_reindex(
                            input_file=fpath,
                            start_chapter_num=start_num,
                            signature_text=sig,
                            output_mode=output_mode,
                            is_silent=is_silent,
                            indent_str=indent_str,
                            keep_original_numbering=keep_original
                        ) 
                    except Exception as e:
                        print(f"‚ùå L·ªói file {fpath}: {e}")
                        log_error(os.path.basename(fpath), f"Critical Error: {e}")
                        traceback.print_exc()            
            print("\n‚úÖ HO√ÄN T·∫§T T·∫§T C·∫¢ T√ÅC V·ª§.")            
        except Exception as e: 
            print(f"‚ùå L·ªói Critical: {e}")
            log_error("SYSTEM", f"Critical System Error: {e}")
            traceback.print_exc()
            input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")                      
        if input("\nTi·∫øp t·ª•c x·ª≠ l√Ω ƒë·ª£t kh√°c? (y/n): ").lower() == 'n': break
